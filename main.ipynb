{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import pandas as pd\n",
    "from math import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shop = pd.read_csv('../ants_data/训练数据-ccf_first_round_shop_info.csv')\n",
    "train = pd.read_csv('../ants_data/训练数据-ccf_first_round_user_shop_behavior.csv')\n",
    "test = pd.read_csv('../ants_data/AB榜测试集-evaluation_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (list(shop.ix[:,'mall_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2): # 经度1，纬度1，经度2，纬度2 （十进制度数）  \n",
    "    \"\"\" \n",
    "    Calculate the great circle distance between two points  \n",
    "    on the earth (specified in decimal degrees) \n",
    "    \"\"\"  \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])  \n",
    "    dlon = lon2 - lon1   \n",
    "    dlat = lat2 - lat1   \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2  \n",
    "    c = 2 * asin(sqrt(a))   \n",
    "    r = 6371 \n",
    "    return c * r * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcDistance(Lat_A, Lng_A, Lat_B, Lng_B):\n",
    "    \"\"\"\n",
    "        # input Lat_A 纬度A\n",
    "        # input Lng_A 经度A\n",
    "        # input Lat_B 纬度B\n",
    "        # input Lng_B 经度B\n",
    "        # output distance 距离(km)\n",
    "    \"\"\"\n",
    "    ra = 6378.140  # 赤道半径 (km)\n",
    "    rb = 6356.755  # 极半径 (km)\n",
    "    flatten = (ra - rb) / ra  # 地球扁率\n",
    "    rad_lat_A, rad_lng_A, rad_lat_B, rad_lng_B = map(radians, [Lat_A, Lng_A, Lat_B, Lng_B])  \n",
    "    pA = atan(rb / ra * tan(rad_lat_A))\n",
    "    pB = atan(rb / ra * tan(rad_lat_B))\n",
    "    xx = acos(sin(pA) * sin(pB) + cos(pA) * cos(pB) * cos(rad_lng_A - rad_lng_B))\n",
    "    print('pA',Lng_A,Lat_A,'pB',Lat_B,Lng_B)\n",
    "    c1 = (sin(xx) - xx) * (sin(pA) + sin(pB)) ** 2 / cos(xx / 2) ** 2\n",
    "    c2 = (sin(xx) + xx) * (sin(pA) - sin(pB)) ** 2 / sin(xx / 2) ** 2\n",
    "    dr = flatten / 8 * (c1 - c2)\n",
    "    distance = ra * (xx + dr)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Lat_A=32.060255; Lng_A=118.796877\n",
    "Lat_B=39.904211; Lng_B=116.407395\n",
    "distance=calcDistance(Lat_A,Lng_A,Lat_B,Lng_B)\n",
    "print('(Lat_A, Lng_A)=({0:10.3f},{1:10.3f})'.format(Lat_A,Lng_A))\n",
    "print('(Lat_B, Lng_B)=({0:10.3f},{1:10.3f})'.format(Lat_B,Lng_B))\n",
    "print('Distance={0:10.3f} km'.format(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nearest_shop_id(longitude, latitude, shop_ids_by_mall_id):\n",
    "    #map_data = map(lambda lat, lng: calcDistance(lat, lng, latitude, longitude), shop_ids_by_mall_id['latitude'], shop_ids_by_mall_id['longitude'])\n",
    "    map_data = map(lambda lng, lat: haversine(lng, lat, longitude, latitude), shop_ids_by_mall_id['longitude'], shop_ids_by_mall_id['latitude'])\n",
    "    data = list(map_data)\n",
    "    shop_ids_by_mall_id = shop_ids_by_mall_id.reset_index(drop=True)\n",
    "    return min(data),shop_ids_by_mall_id.ix[data.index(min(data))]['shop_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['shop_id']='s_xxx'\n",
    "n_samples = test.shape[0]\n",
    "for i in range(n_samples):\n",
    "    mall_id = test.ix[i]['mall_id']\n",
    "    shop_ids_by_mall_id = shop[shop.mall_id == mall_id]\n",
    "    min_dist, nn_shop_id = get_nearest_shop_id(test.ix[i]['longitude'], test.ix[i]['latitude'], shop_ids_by_mall_id)\n",
    "    test.loc[i,'shop_id']= nn_shop_id\n",
    "    print (\"sample_num: \", i, \"min_dist:\", min_dist, \" shop_id:\", test.ix[i]['shop_id'])\n",
    "test.ix[:,['row_id','shop_id']].to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['shop_id']='s_xxx'\n",
    "mall_ids = list( shop.ix[:,'mall_id'].unique() )\n",
    "for mall_id in mall_ids:\n",
    "        mall_id = 'm_5085'\n",
    "        shop_ids_by_mall_id = shop[shop.mall_id == mall_id]\n",
    "        \n",
    "        #print(shop_ids_by_mall_id)\n",
    "        data_with_mall_id = pd.merge(shop_ids_by_mall_id, train.ix[:,['wifi_infos','shop_id']],on='shop_id')\n",
    "        \n",
    "        # get all shops\n",
    "        shops = list(data_with_mall_id.ix[:,'shop_id'].unique())\n",
    "        \n",
    "        # get all wifis\n",
    "        wifis = set()\n",
    "        for wifi in data_with_mall_id.ix[:,'wifi_infos']:\n",
    "            for _wifi in wifi.split(';'):\n",
    "                wifis.add(_wifi.split('|')[0])\n",
    "        wifis = list(wifis)\n",
    "        print(len(wifis))\n",
    "        with open('data/'+str(mall_id)+'_shops.pkl','wb') as f:\n",
    "                pickle.dump(shops,f)\n",
    "        with open('data/'+str(mall_id)+'_wifis.pkl','wb') as f:\n",
    "                pickle.dump(wifis,f)\n",
    "                \n",
    "        with open('data/'+str(mall_id)+'_shops.pkl','rb') as f:\n",
    "                shops = pickle.load(f)\n",
    "                print(shops)\n",
    "        print(len(shops))\n",
    "        data_with_mall_id.drop(['category_id','longitude','latitude','price','mall_id'], axis=1, inplace=True)\n",
    "        \n",
    "        # add more features into wifis here\n",
    "        new_X = pd.DataFrame(columns=range(10))\n",
    "        new_Y = list()\n",
    "        _n_samples = data_with_mall_id.shape[0]\n",
    "        for i in range(_n_samples):\n",
    "            print(i,_n_samples)\n",
    "            shop_id = data_with_mall_id.ix[i]['shop_id']\n",
    "            new_Y.append(shops.index(shop_id))\n",
    "            wifi_infos = data_with_mall_id.ix[i]['wifi_infos'].split(';')\n",
    "            for j in range(len(wifi_infos)):\n",
    "                _wifi = wifi_infos[j].split('|')\n",
    "                new_X.at[i,j]=str(wifis.index(_wifi[0]))+':'+str(_wifi[1])\n",
    "        new_Y = pd.DataFrame(new_Y,columns=['shop_id'])\n",
    "        train_data_by_mall_id = pd.concat([new_Y, new_X], axis=1)\n",
    "        # shuffle samples\n",
    "        train_data_by_mall_id=train_data_by_mall_id.sample(frac=1)\n",
    "        train_data_by_mall_id.to_csv(\"data/\"+str(mall_id)+'.csv',index=False,header=None)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "raw_data = load_svmlight_file('m_5085.csv')\n",
    "\n",
    "train = raw_data[0].toarray()\n",
    "label = raw_data[1]\n",
    "\n",
    "sz = train.shape\n",
    "\n",
    "kfolds = 0.7\n",
    "\n",
    "train_X = train[:int(sz[0] * kfolds), :]\n",
    "test_X = train[int(sz[0] * kfolds):, :]\n",
    "\n",
    "train_Y = label[:int(sz[0] * kfolds)]\n",
    "test_Y = label[int(sz[0] * kfolds):]\n",
    "\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)\n",
    "xg_train = xgb.DMatrix(train_X, label=train_Y)\n",
    "xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "\n",
    "#num_class = dtrain.get_label().shape[0]\n",
    "#params = {'max_depth':3,'num_class':num_class,'objective':'multi:softmax','silent':1}\n",
    "#num_boost_round = 3\n",
    "#model = xgb.train(params, dtrain, num_boost_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11)\n",
      "   0        1         2         3         4         5         6         7   \\\n",
      "0   3  732:-75  1132:-64  1314:-54  1582:-78  2393:-80  3647:-27  3717:-80   \n",
      "1  57  544:-72   732:-38  1132:-86  1461:-91  1822:-89  2140:-38  2224:-74   \n",
      "\n",
      "         8         9         10  \n",
      "0  3934:-80       NaN       NaN  \n",
      "1  3245:-35  3647:-89  3717:-74  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('data/m_4543.csv', header=None)\n",
    "sz = train.shape\n",
    "print(sz)\n",
    "for i in range(sz[0]):\n",
    "    nan_number = train.ix[i,1:][train.ix[i,1:].isnull()].shape[0]\n",
    "    ordered_list=sorted(train.ix[i,1:][~train.ix[i,1:].isnull()],key=lambda data: int(data.split(':')[0]))\n",
    "    # filter duplicate \n",
    "    filtered_ordered_list = []\n",
    "    counter = Counter([elem.split(':')[0] for elem in ordered_list])\n",
    "    for k,v in counter.items():\n",
    "        _list = [elem for elem in ordered_list if elem.split(':')[0] == k]\n",
    "        if v == 1:\n",
    "            filtered_ordered_list.extend(_list)\n",
    "        if v > 1:\n",
    "            nan_number += v - 1\n",
    "            filtered_ordered_list.append(_list[0])\n",
    "    for j in range(nan_number):\n",
    "        filtered_ordered_list.append('NaN')\n",
    "    train.ix[i,1:]= filtered_ordered_list\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2393:-75', '1132:-64', '1314:-54', '1314:-78', '2393:-80']\n",
      "['2393:-75', '2393:-80']\n",
      "['1132:-64']\n",
      "['1314:-54', '1314:-78']\n",
      "['2393:-75', '1132:-64', '1314:-54', 'NaN', 'NaN'] 2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tokens = ['2393:-75', '1132:-64', '1314:-54', '1314:-78', '2393:-80']\n",
    "print(tokens)\n",
    "data = []\n",
    "nan_number = 0\n",
    "counter = Counter([elem.split(':')[0] for elem in tokens])\n",
    "for k,v in counter.items():\n",
    "    _list = [token for token in tokens if token.split(':')[0] == k]\n",
    "    print(_list)\n",
    "    if v == 1:\n",
    "        data.extend(_list)\n",
    "    if v > 1:\n",
    "        nan_number += v - 1\n",
    "        data.append(_list[0])\n",
    "for i in range(nan_number):\n",
    "    data.append('NaN')\n",
    "print(data,nan_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
